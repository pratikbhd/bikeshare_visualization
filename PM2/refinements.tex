\section{Refinements from Previous Milestone} 
\label{sec:research}

The first project milestone needed changes and improvements in various sections and topics of the project. Much of these changes have been incorporated into this milestone and are embedded in the different sections of the report. Some sections required more changes than the others and hence have been listed out below.

\subsection{Evaluation}
\label{sec:evaluation}

Our project can be broadly categorized as an application based visualization project. We have aimed to use existing open-source data to create visualizations that help users identify trends and patterns in the way bike-share systems are being used in a certain city. Keeping this in mind, our evaluation process will be primarily aimed at user test surveys.
As evident from other visualization research projects [insert source here], volunteers for user surveys can be either Mechanical Turks or a group of people who can be considered as laymen in the field of data visualization. In the case of our project, each project member will select 1-2 test subjects of their own to form a group of 4-6 people. The survey will ask the users to use the visualization developed in the project while we monitor their activities. The analysis step of the survey includes the following two steps:
\begin{itemize}
	\item \textbf{User Q\&A}: In this section of the survey, the volunteers will be asked two types of questions: open-ended and close-ended. The open-ended question pertains to the volunteers answering what they infer from the overall visualization. This gives us a high-level feedback as to whether our choice of visualization fulfills its initial objective. The close-ended questions will be more detailed and can be of the following type:
	\begin{itemize}
		\item Which station is most frequently used during the weekends?
		\item What is the highest length of a bike ride for any given two stations?
		\item Which type of bike share subscribers is more prevalent in a given area?
	\end{itemize}
	We measure various metrics (subjective and objective) while the users answer these questions. Subjective metrics like difficulty in answering the questions and objective metrics like time taken to answer the questions can be used. These metrics provide a good estimate of the effectiveness of our choice of visualization.
	\item \textbf{Visualization Comparison}: In this section of our survey, we present the test subjects with other visualizations that work on the same or similar bike share data. Since the objective of our survey is testing the effectiveness of a visualization design, visualizations that map bike share data from other sources will work as well. Here, the users will be asked to answer a set of questions (similar to the ones above) for both the visualizations and compare the metrics obtained from these visualizations. This section of the survey will be performed considering we find other visualizations that perform the tasks similar to ours.
\end{itemize}
A future direction for our evaluation process can be deploying the visualization online. This exposes our implementation to a much wider audience resulting in a vast set of user inputs to test and work on. This step is beyond the scope of our current project timeline but can be implemented as a future enhancement.